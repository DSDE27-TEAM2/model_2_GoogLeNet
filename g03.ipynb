{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 416s 49s/step - loss: 35.3939 - accuracy: 0.1250 - val_loss: 3.8517 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 271s 31s/step - loss: 2.9600 - accuracy: 0.1607 - val_loss: 2.0055 - val_accuracy: 0.2286\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 266s 30s/step - loss: 2.0782 - accuracy: 0.1643 - val_loss: 2.0066 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 271s 31s/step - loss: 1.8668 - accuracy: 0.2929 - val_loss: 1.9672 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 248s 28s/step - loss: 1.7676 - accuracy: 0.3536 - val_loss: 1.9145 - val_accuracy: 0.2143\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 269s 30s/step - loss: 1.6226 - accuracy: 0.4429 - val_loss: 1.9281 - val_accuracy: 0.2143\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 263s 30s/step - loss: 1.5173 - accuracy: 0.4714 - val_loss: 1.9120 - val_accuracy: 0.2143\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 245s 28s/step - loss: 1.3200 - accuracy: 0.5179 - val_loss: 1.8313 - val_accuracy: 0.2000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 274s 32s/step - loss: 1.1102 - accuracy: 0.6464 - val_loss: 1.9137 - val_accuracy: 0.2143\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 278s 31s/step - loss: 0.9855 - accuracy: 0.6286 - val_loss: 2.0295 - val_accuracy: 0.2286\n",
      "3/3 [==============================] - 2s 566ms/step - loss: 2.0295 - accuracy: 0.2286\n",
      "Test loss: 2.029479742050171\n",
      "Test accuracy: 0.22857142984867096\n",
      "1/1 [==============================] - 1s 603ms/step\n",
      "Predicted emotion: sad\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_image(image_path, img_width, img_height):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img\n",
    "\n",
    "def load_dataset(data_dir, img_width, img_height):\n",
    "    X = []\n",
    "    y = []\n",
    "    emotion_classes = sorted(os.listdir(data_dir))\n",
    "    for i, emotion in enumerate(emotion_classes):\n",
    "        emotion_dir = os.path.join(data_dir, emotion)\n",
    "        if os.path.isdir(emotion_dir):  # Check if the item is a directory\n",
    "            for image_name in os.listdir(emotion_dir):\n",
    "                image_path = os.path.join(emotion_dir, image_name)\n",
    "                try:\n",
    "                    img = cv2.imread(image_path)\n",
    "                    if img is not None:  # Check if the image was loaded successfully\n",
    "                        img = cv2.resize(img, (img_width, img_height))\n",
    "                        img = img.astype('float32') / 255.0\n",
    "                        X.append(img)\n",
    "                        y.append(i)\n",
    "                    else:\n",
    "                        print(f\"Warning: Skipping invalid image file: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}, Skipping image: {image_path}\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = to_categorical(y, num_classes=len(emotion_classes))\n",
    "    return X, y\n",
    "\n",
    "def inception_block(x, filters):\n",
    "    # 1x1 Convolution\n",
    "    conv1x1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    conv3x3 = Conv2D(filters[1], (3, 3), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 5x5 Convolution\n",
    "    conv5x5 = Conv2D(filters[2], (5, 5), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 3x3 MaxPooling followed by 1x1 Convolution\n",
    "    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    conv1x1_pool = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(pool)\n",
    "\n",
    "    # Concatenate all the outputs\n",
    "    inception_output = concatenate([conv1x1, conv3x3, conv5x5, conv1x1_pool], axis=-1)\n",
    "    return inception_output\n",
    "\n",
    "\n",
    "def build_inception_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First Convolutional layer\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # First Inception block\n",
    "    x = inception_block(x, [64, 128, 32, 32])\n",
    "    \n",
    "    # Add more Inception blocks here if needed\n",
    "\n",
    "    # Fully Connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load and preprocess the entire dataset\n",
    "data_dir = '/Users/eunjincho/Documents/workspaces/data_geeks/datasets/'\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "X, y = load_dataset(data_dir, img_width, img_height)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = build_inception_model((img_width, img_height, 3), len(os.listdir(data_dir)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "# Example usage for predicting emotions\n",
    "image_path = '/Users/eunjincho/Documents/workspaces/data_geeks/datasets/anger/anger1.jpg'\n",
    "input_image = preprocess_image(image_path, img_width, img_height)\n",
    "input_image = np.expand_dims(input_image, axis=0)\n",
    "predicted_probs = model.predict(input_image)\n",
    "predicted_emotion_index = np.argmax(predicted_probs)\n",
    "emotion_classes = sorted(os.listdir(data_dir))\n",
    "predicted_emotion = emotion_classes[predicted_emotion_index]\n",
    "print(\"Predicted emotion:\", predicted_emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsde04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
